{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Overview Experiment Guide - Parte 02.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roscibely/Artificial-Intelligence-Course/blob/main/Deep_Learning_Overview_Experiment_Guide_Parte_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDKiIQ2-dC6i"
      },
      "source": [
        "# Description\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NItAvDYWd3dp"
      },
      "source": [
        "This experiment guide introduces the following four experiments:\n",
        "\n",
        "- **Experiment 1**: TensorFlow basics\n",
        "  - This experiment mainly describes the basic syntax of TensorFlow 2.\n",
        "- **Experiment 2**: common modules of TensorFlow 2\n",
        "  - This experiment mainly introduces Keras interfaces.\n",
        "- **Experiment 3**: handwritten text recognition\n",
        "  - This experiment uses basic code to help learners understand how to implement handwritten text recognition through TensorFlow 2.0.\n",
        "- **Experiment 4**: Image Classification\n",
        "  - This experiment is based on how to use TensorFlow 2 and python packages to predict image categories from CIFAR10 image classification dataset. It is hoped that trainees or readers can get started with deep learning and have the basic programming capability of implementing image recognition models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8panofuLCbqP"
      },
      "source": [
        "# 2.0 Common Modules of TensorFlow 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5XvW3dh9f2S"
      },
      "source": [
        "## 2.1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oahEWJqQ9kt6"
      },
      "source": [
        "This section describes the common modules of TensorFlow 2.x, including:\n",
        "\n",
        "- **tf.data**: implements operations on datasets. These operations include reading datasets directly from the memory, reading CSV files, reading TFRecord files, and augmenting data.\n",
        "- **tf.image**: implements processing operations on images. These operations include image luminance transformation, saturation transformation, image size transformation, image rotation, and edge detection.\n",
        "- **tf.gfile**: implements operations on files. These operations include reading, writing, and renaming files, and operating folders.\n",
        "- **tf.keras**: a high-level API used to build and train deep learning models. \n",
        "- **tf.distributions** and other modules\n",
        "\n",
        "This section focuses on the **tf.keras** module to lay a foundation for deep learning modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUulfMrD9_85"
      },
      "source": [
        "## 2.2 Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RInJrF1p-Tnb"
      },
      "source": [
        "Upon completion of this task, you will be able to master the common deep learning modeling interfaces in **tf.keras**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC5f01mI-XYm"
      },
      "source": [
        "## 2.3 Experiment Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEjVPOqt-bRT"
      },
      "source": [
        "### 2.3.1 Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs-q1LoK-lFz"
      },
      "source": [
        "#### 2.3.1.1 Stacking a Model (tf.keras.Sequential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOayUERb-q-L"
      },
      "source": [
        "The most common way to build a model is to stack layers by using **tf.keras.Sequential.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJgTZPLA-wAG"
      },
      "source": [
        "import tensorflow.keras.layers as layers \n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA67b0rE-z5j"
      },
      "source": [
        "#### 2.3.1.2 Building a Functional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKxEnMHQ_IKF"
      },
      "source": [
        "Functional models are mainly built by using **tf.keras.Input** and **tf.keras.Model**, which are more complex than **tf.keras.Sequential** but have a good effect. Variables can be input at the same time or in different phases, and data can be output in different phases. Functional models are preferred if more than one model output is needed.\n",
        "\n",
        "Stacked model (.Sequential) vs. functional model (.Model):\n",
        "\n",
        "The **tf.keras.Sequential** model is a simple stack of layers that cannot represent arbitrary models. You can use the Keras functional API to build complex model topologies such as:\n",
        "\n",
        "- Multi-input models\n",
        "- Multi-output models\n",
        "- Models with shared layers\n",
        "- Models with non-sequential data flows (for example, residual connections)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02VSNoxf_QSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d2f61997-4eac-48a6-a40a-628981b95ae0"
      },
      "source": [
        "#Use the output of the previous layer as the input of the next layer.\n",
        "x = tf.keras.Input(shape=(32,))\n",
        "h1 = layers.Dense(32, activation='relu')(x)\n",
        "h2 = layers.Dense(32, activation='relu')(h1)\n",
        "y = layers.Dense(10, activation='softmax')(h2)\n",
        "model_sample_2 = tf.keras.models.Model(x, y)\n",
        " \n",
        "#Print model information.\n",
        "model_sample_2.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 2,442\n",
            "Trainable params: 2,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZFoEcrNAKBo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "35f733b4-c0d3-41ec-94e2-664ddc7d6a11"
      },
      "source": [
        "# Param numbers (32*32 weights + 32 bias)\n",
        "layer1 = 32 * 32 + 32 \n",
        "layer1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bjMmBKqAYRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "341331e0-48c4-4cb1-cc43-2855b97abc03"
      },
      "source": [
        "layer2 = layer1\n",
        "layer3 = 32 * 10 + 10\n",
        "layer3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FabHZ-OApXU"
      },
      "source": [
        "#### 2.3.1.3 Building a Network Layer (tf.keras.layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzaJxHBAzNo"
      },
      "source": [
        "The **tf.keras.layers** module is used to configure neural network layers. Common classes include:\n",
        "\n",
        "- **tf.keras.layers.Dense**: builds a fully connected layer.\n",
        "- **tf.keras.layers.Conv2D**: builds a two-dimensional convolutional layer.\n",
        "- **tf.keras.layers.MaxPooling2D/AveragePooling2D**: builds a maximum/average pooling layer.\n",
        "- **tf.keras.layers.RNN**: builds a recurrent neural network layer.\n",
        "- **tf.keras.layers.LSTM/tf.keras.layers.LSTMCell**: builds an LSTM network layer/LSTM unit.\n",
        "- **tf.keras.layers.GRU/tf.keras.layers.GRUCell**: builds a GRU unit/GRU network layer.\n",
        "- **tf.keras.layers.Embedding**: converts a positive integer (subscript) into a vector of a fixed size, for example, converts [[4], [20]] into [[0.25, 0.1], [0.6, â€“0.2]]. The embedding layer can be used only as the first model layer.\n",
        "- **tf.keras.layers.Dropout**: builds the dropout layer.\n",
        "  - The following describes **tf.keras.layers.Dense, tf.keras.layers.Conv2D, tf.keras.layers.MaxPooling2D/AveragePooling2D**, and **tf.keras.layers.LSTM/tf.keras.layers.LSTMCell**.\n",
        "\n",
        "Main network configuration parameters in **tf.keras.layers** include:\n",
        "- **activation**: sets the activation function for the layer. By default, the system applies no activation function.\n",
        "- **kernel_initializer** and **bias_initializer**: initialization schemes that create the layer's weights (kernel and bias). This defaults to the Glorot uniform initializer.\n",
        "- **kernel_regularizer** and **bias_regularizer**: regularization schemes that apply to the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, the system applies no regularization function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ukWb2RyBiJW"
      },
      "source": [
        "##### 2.3.1.3.1 tf.keras.layers.Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIiLGnCCDa8K"
      },
      "source": [
        "Main configuration parameters in **tf.keras.layers.Dense** include:\n",
        "\n",
        "- **units**: number of neurons\n",
        "-**activation**: sets the activation function.\n",
        "-**use_bias**: indicates whether to use bias terms. Bias terms are used by default.\n",
        "-**kernel_initializer**: initialization scheme that creates the layer's weight (kernel)\n",
        "-**bias_initializer**: initialization scheme that creates the layer's weight (bias)\n",
        "-**kernel_regularizer**: regularization scheme that applies to the layer's weight (kernel)\n",
        "-**bias_regularizer**: regularization scheme that applies to the layer's weight (bias)\n",
        "-**activity_regularizer**: regular item applied to the output, a regularizer object\n",
        "-**kernel_constraint**: a constraint applied to a weight\n",
        "-**bias_constraint**: a constraint applied to a weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JlQLddwDr5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "03bf08c4-2ab7-4d89-cfc6-c4a9a6b81718"
      },
      "source": [
        "#Create a fully connected layer that contains 32 neurons. Set the activation function to sigmoid.\n",
        "#The activation parameter can be set to a function name string, for example, sigmoid or a function object, for example, tf.sigmoid.\n",
        "layers.Dense(32, activation='sigmoid')\n",
        "layers.Dense(32, activation=tf.sigmoid)\n",
        " \n",
        "#Set kernel_initializer.\n",
        "layers.Dense(32, kernel_initializer=tf.keras.initializers.he_normal)\n",
        "#Set kernel_regularizer to L2 regularization.\n",
        "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f9be3bca278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BALQsDsD3rx"
      },
      "source": [
        "##### 2.3.1.3.2 tf.keras.layers.Conv2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5wTfxlUD_3P"
      },
      "source": [
        "Main configuration parameters in tf.keras.layers.Conv2D include:\n",
        "\n",
        "- **filters**: number of convolution kernels (output dimensions)\n",
        "- **kernel_size**: width and length of a convolution kernel\n",
        "-**strides**: convolution step\n",
        "-**padding**: zero padding policy\n",
        "\n",
        "When **padding** is set to **valid**, only valid convolution is performed, that is, boundary data is not processed. When **padding** is set to **same**, the convolution result at the boundary is reserved, and consequently, the output shape is usually the same as the input shape.\n",
        "\n",
        "- **activation**: sets the activation function.\n",
        "- **data_format**: data format, set to **channels_first** or **channels_last**. For example, for a 128 x 128 RGB image, data is organized as (3, 128, 128) if the value is **channels_first**, and (128, 128, 3) if the value is **channels_last**. The default value of this parameter is the value specified in **~/.keras/keras.json**. If this parameter has never been set, the default value is **channels_last**.\n",
        "\n",
        "Other parameters include **use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraints**, and **bias_constraints**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfXhyHt9Erp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5f58674d-7981-43b4-e721-1c7538acfb3a"
      },
      "source": [
        "layers.Conv2D(64,[1,1],2,padding='same',activation=\"relu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f9be3c8beb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOY3xLLXE2SP"
      },
      "source": [
        "##### 2.3.1.3.3 tf.keras.layers.MaxPooling2D/AveragePooling2D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h316clR3FWcD"
      },
      "source": [
        "Main configuration parameters in **tf.keras.layers.MaxPooling2D/AveragePooling2D** include:\n",
        "\n",
        "- **pool_size**: size of the pooled kernel. For example, if the matrix (2, 2) is used, the picture becomes half of the original length in both dimensions. If this parameter is set to an integer, the integer is the values of all dimensions.\n",
        "- **strides**: step\n",
        "\n",
        "Other parameters include **padding** and **data_format**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_HqsL5VFY_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "11c8f840-7c39-4b82-c60b-983ae67dcc33"
      },
      "source": [
        "layers.MaxPooling2D(pool_size=(2,2),strides=(2,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f9be3bca550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVaQb3yUFpv3"
      },
      "source": [
        "##### 2.3.1.3.4 tf.keras.layers.LSTM/tf.keras.layers.LSTMCell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owutseu5Fv9E"
      },
      "source": [
        "Main configuration parameters in **tf.keras.layers.LSTM/tf.keras.layers.LSTMCell** include:\n",
        "\n",
        "- **units**: output dimension\n",
        "- **input_shape** (**timestep** and **input_dim**): **timestep** can be set to **None**, and **input_dim** indicates the input data dimension.\n",
        "- **activation**: sets the activation function.\n",
        "- **recurrent_activation**: activation function to use for the recurrent step\n",
        "- **return_sequences**: If the value is **True**, the system returns the full sequence. If the value is **False**, the system returns the output in the last cell of the output sequence.\n",
        "- **return_state**: Boolean value, indicating whether to return the last state in addition to the output.\n",
        "- **dropout**: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the inputs.\n",
        "- **recurrent_dropout**: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the recurrent state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDRiB2bvF0Bs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "68f02b44-7544-43b8-b8f0-773f4a552574"
      },
      "source": [
        "import numpy as np\n",
        "inputs = tf.keras.Input(shape=(3, 1))\n",
        "lstm = layers.LSTM(1, return_sequences=True)(inputs)\n",
        "model_lstm_1 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
        " \n",
        "inputs = tf.keras.Input(shape=(3, 1))\n",
        "lstm = layers.LSTM(1, return_sequences=False)(inputs)\n",
        "model_lstm_2 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
        " \n",
        "#Sequences t1, t2, and t3\n",
        "data = [[[0.1],\n",
        "  [0.2],\n",
        "  [0.3]]]\n",
        "print(data)\n",
        "print(\"output when return_sequences is set to True\",model_lstm_1.predict(data))\n",
        "print(\"output when return_sequences is set to False\",model_lstm_2.predict(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.1], [0.2], [0.3]]]\n",
            "output when return_sequences is set to True [[[0.01269885]\n",
            "  [0.03437453]\n",
            "  [0.06238829]]]\n",
            "output when return_sequences is set to False [[-0.08377627]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyHDuo3QGa6E"
      },
      "source": [
        "LSTMcell is the implementation unit of the LSTM layer.\n",
        "\n",
        "- LSTM is an LSTM network layer.\n",
        "- LSTMcell is a single-step computing unit, that is, an LSTM unit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23xPVSfPKKw0"
      },
      "source": [
        "#LSTM\n",
        "tf.keras.layers.LSTM(16, return_sequences=True)\n",
        " \n",
        "#LSTMCell\n",
        "x = tf.keras.Input((None, 3))\n",
        "y = layers.RNN(layers.LSTMCell(16))(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0kIpcqKXFc"
      },
      "source": [
        "### 2.3.2 Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cXKa895O04d"
      },
      "source": [
        "#### 2.3.2.1 Model Compilation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzxvq1JJPAXM"
      },
      "source": [
        "After a model is built, you can call compile to configure the learning process of the model:\n",
        "\n",
        "```python\n",
        "compile( optimizer='rmsprop', loss=None, metrics=None, loss_weights=None)\n",
        "```\n",
        "\n",
        "- **optimizer**: optimizer\n",
        "- **loss**: loss function, cross entropy for binary tasks and MSE for regression tasks\n",
        "- **metrics**: model evaluation criteria during training and testing For example, **metrics** can be set to **['accuracy']**. To specify multiple evaluation criteria, set a dictionary, for example, set metrics to **{'output_a':'accuracy'}**.\n",
        "- **loss_weights**: If the model has multiple task outputs, you need to specify a weight for each output when optimizing the global loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR7hH7hYPOVz"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "#Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "             loss=tf.keras.losses.categorical_crossentropy,\n",
        "             metrics=[tf.keras.metrics.categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4il6-wBHPnhN"
      },
      "source": [
        "#### 2.3.2.2 Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ALlv7M3PvNv"
      },
      "source": [
        "```python\n",
        "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
        "```\n",
        "\n",
        "- **x**: input training data\n",
        "- **y**: target (labeled) data\n",
        "- **batch_size**: number of samples for each gradient update The default value is 32.\n",
        "- **epochs**: number of iteration rounds of the training model\n",
        "- **verbose**: log display mode, set to 0, 1, or 2. \n",
        "  - 0: no display\n",
        "  -1: progress bar\n",
        "  - 2: one line for each round\n",
        "- **callbacks**: callback function used during training\n",
        "- **validation_split**: fraction of the training data to be used as validation data\n",
        "- **validation_data**: validation set. This parameter will overwrite validation_split.\n",
        "- **shuffle**: indicates whether to shuffle data before each round of iteration. This parameter is invalid when **steps_per_epoch** is not **None**. \n",
        "- **initial_epoch**: epoch at which to start training (useful for resuming a previous training weight)\n",
        "- **steps_per_epoch**: set to the dataset size or **batch_size**\n",
        "- **validation_steps**: Total number of steps (batches of samples) to validate before stopping. This parameter is valid only when **steps_per_epoch** is specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLa_W-PxP0tf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "136f5237-f258-402d-8734-eb5c77a3eb10"
      },
      "source": [
        "import numpy as np\n",
        "train_x = np.random.random((1000, 36))\n",
        "train_y = np.random.random((1000, 10))\n",
        "val_x = np.random.random((200, 36))\n",
        "val_y = np.random.random((200, 10))\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
        "          validation_data=(val_x, val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 11.8261 - categorical_accuracy: 0.0890 - val_loss: 11.8526 - val_categorical_accuracy: 0.0900\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8255 - categorical_accuracy: 0.0900 - val_loss: 11.8521 - val_categorical_accuracy: 0.0900\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8252 - categorical_accuracy: 0.0900 - val_loss: 11.8517 - val_categorical_accuracy: 0.0900\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8254 - categorical_accuracy: 0.0890 - val_loss: 11.8523 - val_categorical_accuracy: 0.0900\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8256 - categorical_accuracy: 0.0900 - val_loss: 11.8522 - val_categorical_accuracy: 0.0900\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8256 - categorical_accuracy: 0.0900 - val_loss: 11.8521 - val_categorical_accuracy: 0.0900\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8253 - categorical_accuracy: 0.0890 - val_loss: 11.8519 - val_categorical_accuracy: 0.0900\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8252 - categorical_accuracy: 0.0890 - val_loss: 11.8516 - val_categorical_accuracy: 0.0900\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8250 - categorical_accuracy: 0.0890 - val_loss: 11.8514 - val_categorical_accuracy: 0.0900\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.8248 - categorical_accuracy: 0.0890 - val_loss: 11.8511 - val_categorical_accuracy: 0.0900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9be0eb6b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuW1nHajQknr"
      },
      "source": [
        "You can use **tf.data** to build training input pipelines for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJY4k1AeQva9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "fe48a032-8ffe-405c-ad91-1243955e56d3"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "val_dataset = val_dataset.repeat()\n",
        " \n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
        "          validation_data=val_dataset, validation_steps=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layer dense_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 11.8196 - categorical_accuracy: 0.0896 - val_loss: 11.7620 - val_categorical_accuracy: 0.0521\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 11.8277 - categorical_accuracy: 0.0876 - val_loss: 11.7599 - val_categorical_accuracy: 0.0521\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 11.8586 - categorical_accuracy: 0.0919 - val_loss: 11.7579 - val_categorical_accuracy: 0.0521\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 11.8360 - categorical_accuracy: 0.0908 - val_loss: 11.7564 - val_categorical_accuracy: 0.0521\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.8103 - categorical_accuracy: 0.0897 - val_loss: 11.7551 - val_categorical_accuracy: 0.0521\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 11.7892 - categorical_accuracy: 0.0929 - val_loss: 11.7537 - val_categorical_accuracy: 0.0521\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 11.8324 - categorical_accuracy: 0.0897 - val_loss: 11.7519 - val_categorical_accuracy: 0.0521\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.8163 - categorical_accuracy: 0.0897 - val_loss: 11.7503 - val_categorical_accuracy: 0.0521\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.8051 - categorical_accuracy: 0.0919 - val_loss: 11.7492 - val_categorical_accuracy: 0.0521\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.8082 - categorical_accuracy: 0.0929 - val_loss: 11.7481 - val_categorical_accuracy: 0.0521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9be00f2d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTLkirQyQxdm"
      },
      "source": [
        "#### 2.3.2.3 Callback Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsZ99-SZRb0X"
      },
      "source": [
        "\n",
        "A callback function is an object passed to the model to customize and extend the model's behavior during training. You can customize callback functions or use embedded functions in **tf.keras.callbacks**. Common embedded callback functions include:\n",
        "\n",
        "- **tf.keras.callbacks.ModelCheckpoint**: periodically saves models.\n",
        "- **tf.keras.callbacks.LearningRateScheduler**: dynamically changes the learning rate.\n",
        "- **tf.keras.callbacks.EarlyStopping**: stops the training in advance.\n",
        "- **tf.keras.callbacks.TensorBoard**: exports and visualizes the training progress and results with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeVm8b2mTQ7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "f826f712-aae7-4265-ca5c-5424738f1788"
      },
      "source": [
        "#Set hyperparameters.\n",
        "Epochs = 10\n",
        " \n",
        "#Define a function for dynamically setting the learning rate.\n",
        "def lr_Scheduler(epoch):\n",
        "    if epoch > 0.9 * Epochs:\n",
        "        lr = 0.0001\n",
        "    elif epoch > 0.5 * Epochs:\n",
        "        lr = 0.001\n",
        "    elif epoch > 0.25 * Epochs:\n",
        "        lr = 0.01\n",
        "    else:\n",
        "        lr = 0.1\n",
        "        \n",
        "    print(lr)\n",
        "    return lr\n",
        "            \n",
        " \n",
        "callbacks = [\n",
        "    #Early stopping:\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        #Metric for determining whether the model performance has no further improvement\n",
        "        monitor='val_loss',\n",
        "        #Threshold for determining whether the model performance has no further improvement\n",
        "        min_delta=1e-2,\n",
        "        #Number of epochs in which the model performance has no further improvement\n",
        "        patience=2),\n",
        "    \n",
        "    #Periodically save models.\n",
        "     tf.keras.callbacks.ModelCheckpoint(\n",
        "        #Model path\n",
        "        filepath='testmodel_{epoch}.h5',\n",
        "        #Whether to save the optimal model.\n",
        "        save_best_only=True,\n",
        "        #Monitored metric\n",
        "        monitor='val_loss'),\n",
        "    \n",
        "    #Dynamically change the learning rate.\n",
        "    tf.keras.callbacks.LearningRateScheduler(lr_Scheduler),\n",
        "    \n",
        "    #Use TensorBoard.\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        " \n",
        "model.fit(train_x, train_y, batch_size=16, epochs=Epochs,callbacks=callbacks, validation_data=(val_x, val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n",
            "Epoch 1/10\n",
            "\r 1/63 [..............................] - ETA: 0s - loss: 11.8669 - categorical_accuracy: 0.2500WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_train_batch_end` time: 0.0362s). Check your callbacks.\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 12.0383 - categorical_accuracy: 0.0890 - val_loss: 11.8999 - val_categorical_accuracy: 0.0950\n",
            "0.1\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 12.0968 - categorical_accuracy: 0.0950 - val_loss: 11.9566 - val_categorical_accuracy: 0.1200\n",
            "0.1\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 12.2010 - categorical_accuracy: 0.1100 - val_loss: 12.1744 - val_categorical_accuracy: 0.1200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9bdf0175f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq0MRz3QTism"
      },
      "source": [
        "#### 2.3.2.4 Evaluation and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTGudEtPT6Ow"
      },
      "source": [
        "Evaluation and prediction functions: **tf.keras.Model.evaluate** and **tf.keras.Model.predict**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWpDudIoT_jJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3147d739-5342-462c-fb3d-6baf7470d8b4"
      },
      "source": [
        "#Model evaluation\n",
        "test_x = np.random.random((1000, 36))\n",
        "test_y = np.random.random((1000, 10))\n",
        "model.evaluate(test_x, test_y, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 12.2724 - categorical_accuracy: 0.0890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.2723970413208, 0.08900000154972076]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKUAl2otUBgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "25ee8f2e-e54f-4f4a-a3f2-8401b55ec61e"
      },
      "source": [
        "#Model prediction\n",
        "pre_x = np.random.random((10, 36))\n",
        "result = model.predict(test_x,)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.08740149 0.09348525 0.19208874 ... 0.11176775 0.18140036 0.06074111]\n",
            " [0.06755098 0.06422394 0.17860973 ... 0.09259084 0.21146445 0.04909515]\n",
            " [0.12066569 0.11835348 0.12646042 ... 0.15002887 0.2147491  0.03346167]\n",
            " ...\n",
            " [0.11750468 0.03414055 0.11132252 ... 0.1242044  0.23281755 0.03624053]\n",
            " [0.14516938 0.03110421 0.21943997 ... 0.17944635 0.09487376 0.03716444]\n",
            " [0.15893438 0.08574913 0.14549519 ... 0.13794138 0.12710859 0.04806716]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQWk7ogHUEd_"
      },
      "source": [
        "### 2.3.3 Model Saving and Restoration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZv_7w2eUNcE"
      },
      "source": [
        "#### 2.3.3.1 Saving and Restoring an Entire Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od10IePXUR7l"
      },
      "source": [
        "import numpy as np\n",
        "#Save models.\n",
        "model.save('the_save_model.h5')\n",
        "#Import models.\n",
        "new_model = tf.keras.models.load_model('the_save_model.h5')\n",
        "new_prediction = new_model.predict(test_x)\n",
        "#np.testing.assert_allclose: determines whether the similarity between two objects exceeds the specified tolerance. If yes, the system displays an exception.\n",
        "#atol: specified tolerance\n",
        "np.testing.assert_allclose(result, new_prediction, atol=1e-6) # Prediction results are the same."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp66mFc6UUtz"
      },
      "source": [
        "After a model is saved, you can find the corresponding weight file in the corresponding folder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-GHJupUmCZ"
      },
      "source": [
        "#### 2.3.3.2 Saving and Loading Network Weights Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE2nP57tUqmz"
      },
      "source": [
        "If the weight name is suffixed with **.h5** or **.keras**, save the weight as an HDF5 file, or otherwise, save the weight as a TensorFlow checkpoint file by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BLt7a5MUwzB"
      },
      "source": [
        "model.save_weights('model_weights')\n",
        "model.save_weights('model_weights.h5')\n",
        "#Load the weights.\n",
        "model.load_weights('model_weights')\n",
        "model.load_weights('model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}