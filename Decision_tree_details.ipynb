{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_tree_details.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDzXwvUp+PIn1SUfYBIA2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roscibely/Artificial-Intelligence-Course/blob/main/Decision_tree_details.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQBwdcG61j7m"
      },
      "source": [
        "# 3.1 Introduction\n",
        "\n",
        "## 3.1.1 About This Experiment\n",
        "\n",
        "This experiment focuses on the decision tree algorithm through the basic Python code.\n",
        "\n",
        "It mainly uses Numpy module, Pandas module and Math module. We will implement the CART treeï¼ˆClassification and Regressiontree models) in this experiment.\n",
        "You have to download the dataset before this experiment through this link:\n",
        "https://data-certification.obs.cn-east-2.myhuaweicloud.com/ENG/HCIA-AI/V3.0/ML-Dataset.rar \n",
        "\n",
        "### 3.1.2 Objectives\n",
        "\n",
        "The purpose of this experiment is as follows:\n",
        "\n",
        "- Familiar with basic Python syntax\n",
        "\n",
        "- Master the principle of Classification tree and implement with Python code\n",
        "\n",
        "- Master the principle of Regression tree and implement with Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWciFFZo2i13"
      },
      "source": [
        "# 3.2 Experiment Code\n",
        "\n",
        "### 3.2.1 Import the modules you need\n",
        "\n",
        "Pandas is a tabular data processing module.\n",
        "\n",
        "Math is mainly used for mathematical calculations.\n",
        "\n",
        "Numpy is the basic computing module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzn3Q-jN0Nhh"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdUoDaCg24Nm"
      },
      "source": [
        "### 3.2.2 Superparameter definition section\n",
        "\n",
        "Here you can choose to use Classification tree or Regression tree. Specifies the address of the dataset. Get feature name. Determine whether the algorithm matches the data set\n",
        "algorithm = \"Regression\" # Algorithm: Classification, Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dku8Ms1e12Yr"
      },
      "source": [
        "algorithm = \"Classification\" # Algorithm: Classification, Regression\n",
        "# Dataset1: Text features and text labels\n",
        "#df = pd.read_csv(\"D:/Code/DecisionTreee/candidate/decision-trees-for-ml-master/decision-trees-for-ml-master/dataset/golf.txt\")\n",
        "# Dataset2: Mix features and Numeric labels, here you have to change the path to yours.\n",
        "df = pd.read_csv(\"golf4.txt\")\n",
        "# This dictionary is used to store feature types of continuous numeric features and discrete literal features for subsequent judgment\n",
        "dataset_features = dict()\n",
        "num_of_columns = df.shape[1]-1\n",
        "#The data type of each column of the data is saved for displaying the data name\n",
        "for i in range(0, num_of_columns):\n",
        "  #Gets the column name and holds the characteristics of a column of data by column\n",
        "  column_name = df.columns[i]\n",
        "  #Save the type of the data\n",
        "  dataset_features[column_name] = df[column_name].dtypes\n",
        "  # The size of the indent when display\n",
        "root = 1\n",
        "# If the algorithm selects a regression tree but the label is not a continuous value, an error is reported\n",
        "if algorithm == 'Regression':\n",
        "  if df['Decision'].dtypes == 'object':\n",
        "    raise ValueError('dataset wrong')\n",
        "# If the tag value is continuous, the regression tree must be used\n",
        "if df['Decision'].dtypes != 'object':\n",
        "  algorithm = 'Regression'\n",
        "  global_stdev = df['Decision'].std(ddof=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf3dg9F63A8h"
      },
      "source": [
        "### 3.2.3 Define the functions required to complete the algorithm\n",
        "\n",
        "ProcessContinuousFeatures: Used to convert a continuous digital feature into a category feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kht6Re2dx0"
      },
      "source": [
        "# This function is used to handle numeric characteristics\n",
        "def processContinuousFeatures(cdf, column_name, entropy):\n",
        "  # Numerical features are arranged in order\n",
        "  unique_values = sorted(cdf[column_name].unique())\n",
        "  subset_ginis = [];\n",
        "  subset_red_stdevs = []\n",
        "  for i in range(0, len(unique_values) - 1):\n",
        "    threshold = unique_values[i]\n",
        "    # Find the segmentation result if the first number is used as the threshold\n",
        "    subset1 = cdf[cdf[column_name] <= threshold]\n",
        "    subset2 = cdf[cdf[column_name] > threshold]\n",
        "    # Calculate the proportion occupied by dividing the two parts\n",
        "    subset1_rows = subset1.shape[0];\n",
        "    subset2_rows = subset2.shape[0]\n",
        "    total_instances = cdf.shape[0]\n",
        "    # In the text feature part, entropy is calculated by using the cycle\n",
        "\n",
        "    # and in the numeric part, entropy is calculated by using the two groups after segmentation,\n",
        "# and the degree of entropy reduction is obtained\n",
        "if algorithm == 'Classification':\n",
        "decision_for_subset1 = subset1['Decision'].value_counts().tolist()\n",
        "decision_for_subset2 = subset2['Decision'].value_counts().tolist()\n",
        "gini_subset1 = 1;\n",
        "gini_subset2 = 1\n",
        "for j in range(0, len(decision_for_subset1)):\n",
        "gini_subset1 = gini_subset1 - math.pow((decision_for_subset1[j] / subset1_rows), 2)\n",
        "for j in range(0, len(decision_for_subset2)):\n",
        "gini_subset2 = gini_subset2 - math.pow((decision_for_subset2[j] / subset2_rows), 2)\n",
        "gini = (subset1_rows / total_instances) * gini_subset1 + (subset2_rows / total_instances) *\n",
        "gini_subset2\n",
        "subset_ginis.append(gini)\n",
        "# Take standard deviation as the judgment basis, calculate the decrease value of standard\n",
        "deviation at this time\n",
        "elif algorithm == 'Regression':\n",
        "superset_stdev = cdf['Decision'].std(ddof=0)\n",
        "subset1_stdev = subset1['Decision'].std(ddof=0)\n",
        "subset2_stdev = subset2['Decision'].std(ddof=0)\n",
        "threshold_weighted_stdev = (subset1_rows / total_instances) * subset1_stdev + (\n",
        "subset2_rows / total_instances) * subset2_stdev\n",
        "threshold_reducted_stdev = superset_stdev - threshold_weighted_stdev\n",
        "subset_red_stdevs.append(threshold_reducted_stdev)\n",
        "#Find the index of the split value\n",
        "if algorithm == \"Classification\":\n",
        "winner_one = subset_ginis.index(min(subset_ginis))\n",
        "elif algorithm == \"Regression\":\n",
        "winner_one = subset_red_stdevs.index(max(subset_red_stdevs))\n",
        "# Find the corresponding value according to the index\n",
        "winner_threshold = unique_values[winner_one]\n",
        "# Converts the original data column to an edited string column.\n",
        "# Characters smaller than the threshold are modified with the <= threshold value\n",
        "cdf[column_name] = np.where(cdf[column_name] <= winner_threshold, \"<=\" +\n",
        "str(winner_threshold),\">\" + str(winner_threshold))\n",
        "return cdf"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}